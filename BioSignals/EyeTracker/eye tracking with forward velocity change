"""Orlosky Pupil Detector — *live camera edition*

This is a refactor of the original **OrloskyPupilDetector.py** to let you pick a
web cam or a video file at launch (the same little Tk GUI that the 3 D tracker
uses).  All the pupil finding logic is unchanged; we've just:

* added a camera selector / file browser GUI
* broken the video loop out into a `process_camera()` routine
* kept `process_video()` for offline files

Run it with `python OrloskyPupilDetectorLive.py`, choose *Start Camera*, and hit
`Space` to pause, `D` for debug overlays, `Q` to quit.
"""

import cv2
import numpy as np
import random
import math
import tkinter as tk
from tkinter import ttk, filedialog
import os
import matplotlib.pyplot as plt  # only used when debug‑mode is on
import subprocess
from hexadecimal import decimal_to_hex  # Import the hex conversion function
import serial
import time

# Open the serial connection (replace with your actual COM port)
# ser = serial.Serial('COM4', 115200)
last_sent_x = None  # To avoid re-sending the same value


# ---------------------------------------------------------------------------
# ►►  The pupil‑detection functions below are **identical** to the originals
#     in OrloskyPupilDetector.py  citeturn6file0
# ---------------------------------------------------------------------------

def rotate_frame(frame: np.ndarray) -> np.ndarray:
    """Rotate the frame 180 degrees."""
    return cv2.rotate(frame, cv2.ROTATE_180)

def crop_to_aspect_ratio(image, width=640, height=480):
    current_height, current_width = image.shape[:2]
    desired_ratio = width / height
    current_ratio = current_width / current_height
    if current_ratio > desired_ratio:
        new_width = int(desired_ratio * current_height)
        offset = (current_width - new_width) // 2
        cropped = image[:, offset : offset + new_width]
    else:
        new_height = int(current_width / desired_ratio)
        offset = (current_height - new_height) // 2
        cropped = image[offset : offset + new_height, :]
    return cv2.resize(cropped, (width, height))

# (…the rest of the helper functions are copied verbatim; scroll ↓ if you want
#  to tweak the algorithm. Nothing below here touches the camera settings.)

# --- binary‑threshold helpers ------------------------------------------------

def apply_binary_threshold(image, darkest_pixel_value, added_threshold):
    _, out = cv2.threshold(image, darkest_pixel_value + added_threshold, 255, cv2.THRESH_BINARY_INV)
    return out

def get_darkest_area(image):
    ignore = 20
    step   = 10
    win    = 20
    skip   = 5
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Calculate center and bounds for 180x140 search area
    center_y = gray.shape[0] // 2
    center_x = gray.shape[1] // 2
    search_height = 160
    search_width = 210
    
    # Calculate bounds
    start_y = max(ignore, center_y - search_height//2)
    end_y = min(gray.shape[0] - ignore, center_y + search_height//2)
    start_x = max(ignore, center_x - search_width//2)
    end_x = min(gray.shape[1] - ignore, center_x + search_width//2)
    
    lowest_sum, darkest_pt = float("inf"), None
    for y in range(start_y, end_y, step):
        for x in range(start_x, end_x, step):
            block = gray[y : y + win : skip, x : x + win : skip]
            s = int(block.sum())
            if s < lowest_sum:
                lowest_sum, darkest_pt = s, (x + win // 2, y + win // 2)
    return darkest_pt

def mask_outside_square(img, center, size):
    x, y = center
    half = size // 2
    mask = np.zeros_like(img)
    mask[max(0, y - half) : min(img.shape[0], y + half), max(0, x - half) : min(img.shape[1], x + half)] = 255
    return cv2.bitwise_and(img, mask)

# (…ellipse helpers unchanged…)
# ---------------------------------------------------------------------------
#   ellipse utilities (filter_contours_by_area_and_return_largest, etc.)
# ---------------------------------------------------------------------------

def optimize_contours_by_angle(contours, image):
    if len(contours) < 1:
        return contours
    pts = np.concatenate(contours[0], axis=0)
    spacing = max(1, len(pts) // 25)
    centroid = np.mean(pts, axis=0)
    good = []
    for i in range(len(pts)):
        p = pts[i]
        p_prev = pts[i - spacing]
        p_next = pts[(i + spacing) % len(pts)]
        v1 = p_prev - p
        v2 = p_next - p
        denom = np.linalg.norm(v1) * np.linalg.norm(v2)
        if denom == 0:
            continue
        angle_ok = np.dot(v1, v2) / denom
        to_centroid = centroid - p
        if np.dot(to_centroid, (v1 + v2) / 2) >= np.cos(np.radians(60)):
            good.append(p)
    return np.array(good, dtype=np.int32).reshape((-1, 1, 2))

def filter_contours_by_area_and_return_largest(contours, pixel_thresh, ratio_thresh):
    best = None
    best_area = 0
    for c in contours:
        a = cv2.contourArea(c)
        if a < pixel_thresh:
            continue
        x, y, w, h = cv2.boundingRect(c)
        ratio = max(w / h, h / w)
        if ratio <= ratio_thresh and a > best_area:
            best, best_area = c, a
    return [best] if best is not None else []

# (check_contour_pixels, check_ellipse_goodness, fit_and_draw_ellipses – same as original)

def check_contour_pixels(contour, shape, dbg=False):
    if len(contour) < 5:
        return [0, 0, None]
    mask_contour = np.zeros(shape, np.uint8)
    cv2.drawContours(mask_contour, [contour], -1, 255, 1)
    ellipse = cv2.fitEllipse(contour)
    mask_thick = np.zeros(shape, np.uint8)
    mask_thin  = np.zeros(shape, np.uint8)
    cv2.ellipse(mask_thick, ellipse, 255, 10)
    cv2.ellipse(mask_thin,  ellipse, 255, 4)
    overlap_thick = cv2.bitwise_and(mask_contour, mask_thick)
    overlap_thin  = cv2.bitwise_and(mask_contour, mask_thin)
    abs_pix = int(np.sum(overlap_thick > 0))
    ratio = (np.sum(overlap_thin > 0) / np.sum(mask_contour > 0)) if np.sum(mask_contour > 0) else 0
    return [abs_pix, ratio, overlap_thin]

def check_ellipse_goodness(bin_img, contour, dbg=False):
    if len(contour) < 5:
        return [0, 0, 0]
    ellipse = cv2.fitEllipse(contour)
    mask = np.zeros_like(bin_img)
    cv2.ellipse(mask, ellipse, 255, -1)
    area = np.sum(mask == 255)
    filled = np.sum((bin_img == 255) & (mask == 255))
    if area == 0:
        return [0, 0, 0]
    skew = min(ellipse[1][0] / ellipse[1][1], ellipse[1][1] / ellipse[1][0])
    return [filled / area, 0, skew]

# ---------------------------------------------------------------------------
#   Frame‑level pipeline – untouched from original script
# ---------------------------------------------------------------------------

def process_frames(th_strict, th_med, th_relax, frame, gray, dark_pt, debug, render):
    best_score = 0
    best_contours = []
    best_img = None
    kernel = np.ones((5, 5), np.uint8)
    
    # Create a center mask (180x140 region)
    center_mask = np.zeros_like(gray)
    center_y = gray.shape[0] // 2
    center_x = gray.shape[1] // 2
    mask_height = 140
    mask_width = 180
    start_y = center_y - mask_height//2
    end_y = center_y + mask_height//2
    start_x = center_x - mask_width//2
    end_x = center_x + mask_width//2
    center_mask[start_y:end_y, start_x:end_x] = 255
    
    for thr_img in (th_relax, th_med, th_strict):
        # Apply center mask to thresholded image
        masked_thr = cv2.bitwise_and(thr_img, center_mask)
        dil = cv2.dilate(masked_thr, kernel, iterations=2)
        contours, _ = cv2.findContours(dil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        biggest = filter_contours_by_area_and_return_largest(contours, 36, 3)
        if biggest and len(biggest[0]) > 5:
            g = check_ellipse_goodness(dil, biggest[0])
            abs_pix, ratio, ov = check_contour_pixels(biggest[0], dil.shape)
            score = g[0] * abs_pix * abs_pix * ratio
            if score > best_score:
                best_score, best_contours, best_img = score, biggest, dil
    if not best_contours:
        return (0, 0), frame  # no ellipse this frame
    opt = [optimize_contours_by_angle(best_contours, gray)]
    if len(opt[0]) <= 5:
        return (0, 0), frame
    ellipse = cv2.fitEllipse(opt[0])
    cv2.ellipse(frame, ellipse, (55, 255, 0), 2)
    cx, cy = map(int, ellipse[0])
    cv2.circle(frame, (cx, cy), 3, (255, 255, 0), -1)
    if render:
        cv2.imshow("Pupil", frame)
    return (cx, cy), frame

# Global variable to store last known pupil ellipse
last_pupil_ellipse = None
# Global variable to store reference point
reference_point = None

def process_frame(frame, debug=False, render=False):
    global last_pupil_ellipse, reference_point
    frame = crop_to_aspect_ratio(frame)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # Define ROI parameters
    ROI_W = 310
    ROI_H = 200
    center_y = frame.shape[0] // 2
    center_x = frame.shape[1] // 2
    
    # Calculate ROI bounds with 40 pixel right offset
    x0 = max(0, center_x - ROI_W//2 + 80)  # Added 40 pixel offset to the right
    y0 = max(0, center_y - ROI_H//2 + 70)
    x0 = min(x0, frame.shape[1] - ROI_W)
    y0 = min(y0, frame.shape[0] - ROI_H)
    
    # Extract ROI
    roi = frame[y0:y0+ROI_H, x0:x0+ROI_W]
    gray_roi = gray[y0:y0+ROI_H, x0:x0+ROI_W]
    
    # Get darkest point in ROI
    dark_pt_roi = get_darkest_area(roi)
    if dark_pt_roi is None:
        return (0, 0), frame
        
    dark_val = gray_roi[dark_pt_roi[1], dark_pt_roi[0]]
    
    # Create thresholded images for ROI
    th_strict = apply_binary_threshold(gray_roi, dark_val, 5)
    th_med = apply_binary_threshold(gray_roi, dark_val, 15)
    th_relax = apply_binary_threshold(gray_roi, dark_val, 25)
    
    # Process frames for pupil detection in ROI
    (cx_roi, cy_roi), _ = process_frames(th_strict, th_med, th_relax, roi, gray_roi, dark_pt_roi, debug, False)
    
    # Detect the iris as a grey circle via HoughCircles
    blur = cv2.medianBlur(gray_roi, 7)
    # Only consider mid-grey intensities (e.g. iris) by pre-masking
    grey_mask = cv2.inRange(blur, 40, 160)
    grey_blur = cv2.bitwise_and(blur, blur, mask=grey_mask)
    
    # Hough parameters tuned for iris scale
    circles = cv2.HoughCircles(
        grey_blur,
        cv2.HOUGH_GRADIENT,
        dp=1.2,
        minDist=ROI_H/2,
        param1=50,
        param2=30,
        minRadius=ROI_W//8,
        maxRadius=ROI_W//2,
    )
    
    iris = None
    if circles is not None:
        # take the circle closest to ROI center
        circles = np.round(circles[0]).astype(int)
        cx0, cy0 = ROI_W//2, ROI_H//2
        iris = min(circles, key=lambda c: (c[0]-cx0)**2 + (c[1]-cy0)**2)
    
    # Draw ROI rectangle
    if render:
        cv2.rectangle(frame, (x0,y0), (x0+ROI_W,y0+ROI_H), (255,0,0), 1)
    
    # Draw pupil
    ellipse_drawn = False
    ellipse_center = None
    if (cx_roi, cy_roi) != (0,0):
        cx_full = cx_roi + x0
        cy_full = cy_roi + y0
        th_imgs = [th_relax, th_med, th_strict]
        best_score = 0
        best_contours = []
        for thr_img in th_imgs:
            kernel = np.ones((5, 5), np.uint8)
            center_mask = np.zeros_like(gray_roi)
            center_y_roi = gray_roi.shape[0] // 2
            center_x_roi = gray_roi.shape[1] // 2
            mask_height = 140
            mask_width = 180
            start_y = center_y_roi - mask_height//2
            end_y = center_y_roi + mask_height//2
            start_x = center_x_roi - mask_width//2
            end_x = center_x_roi + mask_width//2
            center_mask[start_y:end_y, start_x:end_x] = 255
            masked_thr = cv2.bitwise_and(thr_img, center_mask)
            dil = cv2.dilate(masked_thr, kernel, iterations=2)
            contours, _ = cv2.findContours(dil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            biggest = filter_contours_by_area_and_return_largest(contours, 36, 3)
            if biggest and len(biggest[0]) > 5:
                g = check_ellipse_goodness(dil, biggest[0])
                abs_pix, ratio, ov = check_contour_pixels(biggest[0], dil.shape)
                score = g[0] * abs_pix * abs_pix * ratio
                if score > best_score:
                    best_score, best_contours = score, biggest
        if best_contours and len(best_contours[0]) > 5:
            opt = [optimize_contours_by_angle(best_contours, gray_roi)]
            if len(opt[0]) > 5:
                ellipse = cv2.fitEllipse(opt[0])
                ellipse_offset = ((ellipse[0][0] + x0, ellipse[0][1] + y0), ellipse[1], ellipse[2])
                # Draw blue circle and dot instead of green ellipse and dot
                center = (int(ellipse_offset[0][0]), int(ellipse_offset[0][1]))
                radius = int(max(ellipse_offset[1]) / 2) # Approximate radius from major axis
                cv2.circle(frame, center, radius, (255,0,0), 2) # Blue circle
                cv2.circle(frame, center, 4, (255,0,0), -1) # Blue dot
                last_pupil_ellipse = ellipse_offset
                ellipse_drawn = True
                ellipse_center = center
    else:
        cx_full, cy_full = 0, 0
    # If no ellipse was drawn, draw the last known ellipse as a blue circle/dot
    if not ellipse_drawn and last_pupil_ellipse is not None:
        center = (int(last_pupil_ellipse[0][0]), int(last_pupil_ellipse[0][1]))
        radius = int(max(last_pupil_ellipse[1]) / 2) # Approximate radius from major axis
        cv2.circle(frame, center, radius, (255,0,0), 2) # Blue circle
        cv2.circle(frame, center, 4, (255,0,0), -1) # Blue dot
        ellipse_center = center
    # Show deviation from reference point if set
    if reference_point is not None and ellipse_center is not None:
        # Draw red dot at reference point
        cv2.circle(frame, reference_point, 4, (0,0,255), -1)
        
        dy = ellipse_center[1] - reference_point[1]
        dx = ellipse_center[0] - reference_point[0]
        # Invert y deviation and show x first
        cv2.putText(frame, f"Deviation (x,y): ({dx}, {-dy})", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
    
    # Draw iris (REMOVED BLUE CIRCLE)
    # if iris is not None:
    #     ix_full = iris[0] + x0
    #     iy_full = iris[1] + y0
    #     iradius = iris[2]
    #     cv2.circle(frame, (ix_full, iy_full), iradius, (255,0,0), 2)
    
    if render:
        cv2.imshow("Pupil", frame)
    
    return (cx_full, cy_full), frame

# ---------------------------------------------------------------------------
#   **New** camera / video helpers (borrowed from 3D tracker)
# ---------------------------------------------------------------------------

selected_camera = None  # Tkinter variable will live here

def detect_cameras(max_test=10):
    cams = []
    for i in range(max_test):
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
        if cap.isOpened():
            cams.append(i)
            cap.release()
    return cams

def process_dual_cameras():
    # Open only camera 1
    cap_pupil = cv2.VideoCapture(1, cv2.CAP_DSHOW)
    if not cap_pupil.isOpened():
        print("Could not open camera.")
        return

    global reference_point, last_pupil_ellipse
    reference_point = None
    calibration_points = {}  # Store calibration points
    current_calibration_idx = 0
    calibration_order = ['a', 'b', 'c', 'd']
    calibration_complete = False

    # Add a list to store recent pupil coordinates for smoothing
    pupil_coords_history = []
    smoothing_window_size = 10 # Number of frames to average over

    def transform_coordinates(dx, dy):
        # Transform x coordinate based on sign
        if dx < 0:
            
            if dx > -20:
                dx = 0
            else:
                dx = dx

            transformed_x = dx * 1.67
            # Limit to -100
            transformed_x = max(transformed_x, -100)
            
            # Transform dy based on negative dx
            dy = 150 + transformed_x
            # Limit dy to 100
            dy = min(dy, 100)
        else:
            if dx < 20:
                dx = 0
            else:
                dx = dx

            transformed_x = dx * 2.1
            # Limit to +100
            transformed_x = min(transformed_x, 100)
            
            # Transform dy based on positive dx
            dy = 150 - transformed_x
            # Limit dy to 100
            dy = min(dy, 100)
        
        return transformed_x, dy

    while True:
        ret_pupil, frame_pupil = cap_pupil.read()
        if not ret_pupil:
            break

        # Check if calibration points file exists and read it
        if os.path.exists('calibration_points.txt'):
            try:
                with open('calibration_points.txt', 'r') as f:
                    for line in f:
                        dot, x, y = line.strip().split(',')
                        calibration_points[dot] = (int(x), int(y))
                # Delete the file after reading
                os.remove('calibration_points.txt')
            except:
                pass

        # Check for key press events from GUI
        if os.path.exists('key_press.txt'):
            try:
                with open('key_press.txt', 'r') as f:
                    key = f.read().strip()
                    if key == 'y' and not calibration_complete:
                        current_dot = calibration_order[current_calibration_idx]
                        calibration_points[current_dot] = pupil_coords
                        print(f"Calibration point {current_dot} set at: {pupil_coords}")
                        with open('calibration_points.txt', 'w') as f:
                            for dot, coords in calibration_points.items():
                                if coords is not None:
                                    f.write(f"{dot},{coords[0]},{coords[1]}\n")
                    elif key == 't' and not calibration_complete:
                        current_calibration_idx = (current_calibration_idx + 1) % len(calibration_order)
                        # Write current dot to file to notify GUI
                        with open('current_dot.txt', 'w') as f:
                            f.write(calibration_order[current_calibration_idx])
                    elif key == 'a':
                        calibration_complete = True
                        print("Calibration complete. Starting reference point tracking.")
                os.remove('key_press.txt')
            except:
                pass

        # --- Pupil tracking on camera 1 ---
        pupil_coords, frame_pupil = process_frame(frame_pupil, render=False)
        frame_pupil_tracked = frame_pupil.copy()

        # Add current pupil coordinates to history and maintain window size
        if pupil_coords != (0, 0):
            pupil_coords_history.append(pupil_coords)
            if len(pupil_coords_history) > smoothing_window_size:
                pupil_coords_history.pop(0)

        # Calculate smoothed pupil coordinates
        smoothed_pupil_coords = (0, 0)
        if pupil_coords_history:
            sum_x = sum(p[0] for p in pupil_coords_history)
            sum_y = sum(p[1] for p in pupil_coords_history)
            smoothed_pupil_coords = (int(sum_x / len(pupil_coords_history)), int(sum_y / len(pupil_coords_history)))

        # Handle reference point logic
        key = cv2.waitKey(1) & 0xFF
        if key == ord('w'):
            reference_point = pupil_coords
            print(f"Origin reference point set at: {reference_point}")
        elif key == ord('y') and not calibration_complete:
            current_dot = calibration_order[current_calibration_idx]
            calibration_points[current_dot] = pupil_coords
            print(f"Calibration point {current_dot} set at: {pupil_coords}")
            with open('calibration_points.txt', 'w') as f:
                for dot, coords in calibration_points.items():
                    if coords is not None:
                        f.write(f"{dot},{coords[0]},{coords[1]}\n")
        elif key == ord('t') and not calibration_complete:
            current_calibration_idx = (current_calibration_idx + 1) % len(calibration_order)
            with open('current_dot.txt', 'w') as f:
                f.write(calibration_order[current_calibration_idx])
        elif key == ord('a'):
            calibration_complete = True
            print("Calibration complete. Starting reference point tracking.")

        # Draw overlays
        if reference_point is not None:
            # Draw origin reference point
            cv2.circle(frame_pupil_tracked, reference_point, 4, (0,0,255), -1)
            
            # Use smoothed pupil coordinates for deviation calculation
            dy = smoothed_pupil_coords[1] - reference_point[1]
            dx = smoothed_pupil_coords[0] - reference_point[0]

            # Transform coordinates based on origin reference point
            transformed_x, transformed_y = transform_coordinates(-dx, dy)
            
            # Convert transformed_x and transformed_y to hex
            hex_x = decimal_to_hex(int(transformed_x))
            hex_y = decimal_to_hex(int(transformed_y))
            last_sent_x = 0

            if hex_x and hex_x != last_sent_x:
                try:
                    byte_x = int(hex_x, 16)
                    byte_y = int(hex_y, 16)
#                    ser.write(bytes([byte_x, byte_y]))
                    last_sent_x = hex_x
                    time.sleep(0.01)
                except ValueError:
                    print(f"Invalid hex_x: {hex_x}")

            # Display both original and transformed coordinates
            cv2.putText(frame_pupil_tracked, f"Original Deviation (x,y): ({dx}, {-dy})", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
            cv2.putText(frame_pupil_tracked, f"Transformed (x,y): ({hex_x}, {hex_y})", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
        
        # Draw calibration points if available
        for dot, point in calibration_points.items():
            if point is not None:
                cv2.circle(frame_pupil_tracked, point, 4, (255,0,0), -1)  # Blue color
                cv2.putText(frame_pupil_tracked, dot, (point[0]+10, point[1]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)  # Blue text
                # Calculate deviation from this calibration point using smoothed coordinates
                dx = smoothed_pupil_coords[0] - point[0]
                dy = smoothed_pupil_coords[1] - point[1]
                deviation = math.sqrt(dx*dx + dy*dy)
                cv2.putText(frame_pupil_tracked, f"{dot} Deviation: {deviation:.1f}", (10, 110 + 30 * list(calibration_points.keys()).index(dot)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,0,0), 2)  # Blue text
        
        # If calibration is complete, find and display the closest reference point using smoothed coordinates
        if calibration_complete and smoothed_pupil_coords != (0, 0):
            min_deviation = float('inf')
            closest_point = None
            for dot, point in calibration_points.items():
                if point is not None:
                    dx = smoothed_pupil_coords[0] - point[0]
                    dy = smoothed_pupil_coords[1] - point[1]
                    deviation = math.sqrt(dx*dx + dy*dy)
                    if deviation < min_deviation:
                        min_deviation = deviation
                        closest_point = dot
            if closest_point is not None:
                cv2.putText(frame_pupil_tracked, f"Closest to: {closest_point} (Deviation: {min_deviation:.1f})", (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

        cv2.imshow('Pupil Tracking', frame_pupil_tracked)

        if key == ord('q'):
            break

    cap_pupil.release()
    cv2.destroyAllWindows()

# ---------------------------------------------------------------------------
#   Entry‑point
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    process_dual_cameras()
